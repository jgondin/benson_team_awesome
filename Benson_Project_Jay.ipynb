{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benson Team Awesome\n",
    "\n",
    "C/A,UNIT,SCP,STATION,LINENAME,DIVISION,DATE,TIME,DESC,ENTRIES,EXITS\n",
    "\n",
    "\n",
    "|Code      | explanation                                                                                     |\n",
    "|:-------- |:----------------------------------------------------------------------------------------------- | \n",
    "| C/A      | Control Area (A002)                                                                          | \n",
    "| UNIT     | Remote Unit for a station (R051)                                                             | \n",
    "| SCP      | Subunit Channel Position represents an specific address for a device (02-00-00)              | \n",
    "| STATION  | Represents the station name the device is located at                                         | \n",
    "| LINENAME | Represents all train lines that can be boarded at this station                               | \n",
    "|          |   Normally lines are represented by one character.  LINENAME 456NQR repersents train server for | \n",
    "|          |   4, 5, 6, N, Q, and R trains.                                                                  | \n",
    "| DIVISION | Represents the Line originally the station belonged to BMT, IRT, or IND                      | \n",
    "| DATE     | Represents the date (MM-DD-YY)                                                               |   \n",
    "| TIME     | Represents the time (hh:mm:ss) for a scheduled audit event                                   | \n",
    "| DESc     | Represent the \"REGULAR\" scheduled audit event (Normally occurs every 4 hours)                | \n",
    "|          |   1. Audits may occur more that 4 hours due to planning, or troubleshooting activities.         | \n",
    "|          |   2. Additionally, there may be a \"RECOVR AUD\" entry: This refers to a missed audit that was recovered. |\n",
    "|ENTRIES   | The comulative entry register value for a device|\n",
    "|EXIST     | The cumulative exit register value for a device|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import urllib\n",
    "import io\n",
    "import collections as clt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import multiprocessing as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "#data = pd.read_csv('http://web.mta.info/developers/data/nyct/turnstile/turnstile_160402.txt')\n",
    "# enables inline plots, without it plots don't show up in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_data =[]\n",
    "list_weeks = ['160102', '160109', '160116','160130','160206','160213',\n",
    "              '160220','160227','160305','160312','160319','160326','160402']\n",
    "for u in list_weeks:\n",
    "    url = 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_' + u + '.txt'\n",
    "    print(url)\n",
    "    list_data.append(pd.read_csv(url))\n",
    "\n",
    "data = pd.concat(list_data)\n",
    "del list_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.strip()\n",
    "data[\"datetime\"] = data[\"DATE\"] + ' ' + data[\"TIME\"]\n",
    "data.datetime = pd.to_datetime(data.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sort_values(['STATION','datetime'], ascending=[True, True])\n",
    "\n",
    "data['dENTRIES'] = data.ENTRIES.shift(-1) - data.ENTRIES\n",
    "data['dEXITS'] = data.EXITS.shift(-1) - data.EXITS\n",
    "data['dTOTAL'] = data.dENTRIES+ data.dEXITS\n",
    "\n",
    "mask = ((data.dENTRIES >= 0) & (data.dENTRIES < 5000)) | ((data.dEXITS >= 0) & (data.dEXITS < 5000))\n",
    "df = data.ix[mask,:]\n",
    "del mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(data.head())\n",
    "#print(data['STATION'].unique())\n",
    "df = df.groupby(['STATION', 'datetime']).sum()\n",
    "df.reset_index()\n",
    "idx = pd.IndexSlice\n",
    "dt_station = df.loc[idx['A002', 'R051', :, '59 ST'], :]\n",
    "df.reset_index(inplace=True)\n",
    "df.sort_values(['STATION','datetime'], ascending=[True, True])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "st_59_val = df.loc[idx['A002', 'R051', :, '59 ST'], :]\n",
    "\n",
    "st_59_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list(data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = (data.TIME == '00:00:00') | (data.TIME=='01:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datatest = data.ix[mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask2 = (datatest.dENTRIES >= 0) & (datatest.dENTRIES <=5000) & (datatest.dEXITS >= 0) & (datatest.dEXITS <=5000)\n",
    "datatest2 = datatest.ix [mask2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datatest2 = datatest.ix [mask2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = datatest2.groupby([datatest2.DATE,datatest2.STATION]).sum()\n",
    "df = final.add_suffix('_Count').reset_index()\n",
    "mask3 = (datatest2.dEXITS >= 0) & (datatest2.dEXITS <=5000)\n",
    "#Changing to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sort(['dTOTAL_Count'], ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final = datatest2.groupby([datatest2.DATE,datatest2.STATION]).sum()\n",
    "mask3 = (datatest2.dEXITS >= 0) & (datatest2.dEXITS <=5000)\n",
    "df = final.add_suffix('_Count').reset_index()\n",
    "df.sort(['dTOTAL_Count'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_night = data[data['TIME' ==  ]\n",
    "#data.head()\n",
    "raw_readings ={}\n",
    "raw_readings.setdefault(tuple(['AA','BB']), pd.DataFrame()).append(pd.DataFrame(['5','6']))\n",
    "raw_readings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create the keys that is used to make a mask\n",
    "data_dict = clt.OrderedDict()\n",
    "data['id'] = data.iloc[:, 0]\n",
    "for j in range(data.shape[0]):\n",
    "    data_dict.setdefault(tuple(data.ix[j,0:4]), pd.DataFrame())\n",
    "        \n",
    "#drop the keys that is \n",
    "#mask_key = data['id'].drop_duplicates()\n",
    "#mask_ind = np.arange(mask_key.shape[0])\n",
    "#data.id.replace(mask_key.as_matrix(), mask_ind, inplace=True)\n",
    "#test = data.sort_values(['Delta'])\n",
    "#data.drop(['C/A', 'UNIT', 'SCP','STATION'], axis=1, inplace=True)\n",
    "#data.drop(['LINENAME', 'DIVISION', 'DATE','TIME'], axis=1, inplace=True)\n",
    "#print(mask_key.as_matrix())\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initialize the Delta columns as zeros\n",
    "data['Delta_ENTRIES'] = np.zeros(data.shape[0])\n",
    "data['Delta_EXITS'] = np.zeros(data.shape[0])\n",
    "\n",
    "#temporary function to fill in the deltas by selections\n",
    "#a0 = data['C/A'].drop_duplicates()\n",
    "#a1 = data['UNIT'].drop_duplicates()\n",
    "#a2 = data['SCP'].drop_duplicates()\n",
    "#a3 = data['STATION'].drop_duplicates()\n",
    "#for i0 in a0:\n",
    "#    for i1 in a1:\n",
    "        for \n",
    "def fill_in(mask):\n",
    "    data.ix[mask,'Delta_ENTRIES'] = (data.loc[mask, 'ENTRIES'].shift(1) - data.loc[mask, 'ENTRIES'].shift(-1))\n",
    "    data.ix[mask,'Delta_EXITS'] = (data.loc[mask, 'EXITS'].shift(1) - data.loc[mask, 'EXITS'].shift(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in mask_ind:\n",
    "    mask = data['id'].isin(s)\n",
    "    fill_in(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Delta_ENTRIES'] = (data['ENTRIES'] - data['ENTRIES'].shift(-1))\n",
    "data['Delta_EXITS'] = (data['EXITS'] - data['EXITS'].shift(-1))\n",
    "#print(data.head(20))\n",
    "print(data.head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.mask('DIVISION', 'BMT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gmaps\n",
    "data = gmaps.datasets.load_dataset('taxi_rides')\n",
    "gmaps.heatmap(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-58a0d0fd24ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_config_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworld_readable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheme\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pearl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bubble'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'DATE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dTOTAL'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dTOTAL'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'STATION'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxTitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cufflinks/simple-bubble-chart'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#if you go to plotty... all sorts of plots we can use.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cufflinks as cf\n",
    "import plotly.plotly as py\n",
    "A = pd.DataFrame(np.random.randn(4, 4), columns=[\"A\", \"B\", \"C\", \"D\"])\n",
    "#A = A.mask(\"A\", 0.7).mask(\"B\", 0.2)\n",
    "\n",
    "\n",
    "py.sign_in('ynot79', '2r4xdvecbq')\n",
    "\n",
    "##This is the login info you need to use this module\n",
    "\n",
    "import cufflinks as cf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "## if you get an error... \n",
    "\n",
    "##pip install cufflinks --upgrade\n",
    "\n",
    "##pip install plotly --upgrade\n",
    "\n",
    "cf.set_config_file(offline=False, world_readable=True, theme='pearl')\n",
    "\n",
    "df.iplot(kind='bubble', x='DATE', y='dTOTAL', size='dTOTAL', text='STATION', xTitle='test', yTitle='test', filename='cufflinks/simple-bubble-chart')\n",
    "\n",
    "#if you go to plotty... all sorts of plots we can use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
